{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58350d7a",
   "metadata": {},
   "source": [
    "# Phase 3 project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc13a104",
   "metadata": {},
   "source": [
    "## Covid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2526991f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a73ed7a67a2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdependency\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhard_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdependency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmissing_dependencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{dependency}: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mmkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0m__mkl_version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{MajorVersion}.{UpdateVersion}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, plot_roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "from colorama import Fore\n",
    "from colorama import Style\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2be106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid=pd.read_csv('Covid Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2cd6fc",
   "metadata": {},
   "source": [
    "### Description of Dataset\n",
    "\n",
    "About Dataset\n",
    "Context\n",
    "Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus. Most people infected with COVID-19 virus will experience mild to moderate respiratory illness and recover without requiring special treatment. Older people, and those with underlying medical problems like cardiovascular disease, diabetes, chronic respiratory disease, and cancer are more likely to develop serious illness.\n",
    "During the entire course of the pandemic, one of the main problems that healthcare providers have faced is the shortage of medical resources and a proper plan to efficiently distribute them. In these tough times, being able to predict what kind of resource an individual might require at the time of being tested positive or even before that will be of immense help to the authorities as they would be able to procure and arrange for the resources necessary to save the life of that patient.\n",
    "\n",
    "The main goal of this project is to build a machine learning model that, given a Covid-19 patient's current symptom, status, and medical history, will predict whether the patient is in high risk or not.\n",
    "\n",
    "### content\n",
    "The dataset was provided by the Mexican government (link). This dataset contains an enormous number of anonymized patient-related information including pre-conditions. The raw dataset consists of 21 unique features and 1,048,576 unique patients. In the Boolean features, 1 means \"yes\" and 2 means \"no\". values as 97 and 99 are missing data.\n",
    "\n",
    "* sex: 1 for female and 2 for male.\n",
    "* age: of the patient.\n",
    "* classification: covid test findings. Values 1-3 mean that the patient was diagnosed with covid in different degrees. 4 or higher means that the patient is not a carrier of covid or that the test is inconclusive.\n",
    "* patient type: type of care the patient received in the unit. 1 for returned home and 2 for hospitalization.\n",
    "* pneumonia: whether the patient already have air sacs inflammation or not.\n",
    "* pregnancy: whether the patient is pregnant or not.\n",
    "* diabetes: whether the patient has diabetes or not.\n",
    "* copd: Indicates whether the patient has Chronic obstructive pulmonary disease or not.\n",
    "* asthma: whether the patient has asthma or not.\n",
    "* inmsupr: whether the patient is immunosuppressed or not.\n",
    "* hypertension: whether the patient has hypertension or not.\n",
    "* cardiovascular: whether the patient has heart or blood vessels related disease.\n",
    "* renal chronic: whether the patient has chronic renal disease or not.\n",
    "* other disease: whether the patient has other disease or not.\n",
    "* obesity: whether the patient is obese or not.\n",
    "* tobacco: whether the patient is a tobacco user.\n",
    "* usmr: Indicates whether the patient treated medical units of the first, second or third level.\n",
    "* medical unit: type of institution of the National Health System that provided the care.\n",
    "* intubed: whether the patient was connected to the ventilator.\n",
    "* icu: Indicates whether the patient had been admitted to an Intensive Care Unit.\n",
    "* date died: If the patient died indicate the date of death, and 9999-99-99 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10cc22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2f7028",
   "metadata": {},
   "source": [
    "The column 'CLASSIFICATION_FINAL' tells us which patients tested positive for Covid and which ones didn't.\n",
    "Values 1-3 mean that the patient was diagnosed with covid in different degrees. 4 or higher means that the patient is not a carrier of covid or that the test is inconclusive. \n",
    "So since we are interested only in data regarding covid positive patients, we will filter out the rows that have a value greater than 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a3aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['CLASIFFICATION_FINAL'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63384e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.drop(df_covid.loc[df_covid['CLASIFFICATION_FINAL']>3].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['CLASIFFICATION_FINAL'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736d64d8",
   "metadata": {},
   "source": [
    "We still have a good amount of entries left.\n",
    "And now that we made sure our dataframe contains only covid positive patients, I need to decide which one should be the target variable. <br>The possible ones are:'patient type', 'usmr', 'medical unit', 'icu', 'date died'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD MARKDOWN to describe the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b6ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['USMER'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['PATIENT_TYPE'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f6a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This could be good but it is imbalanced. But maybe even like this it is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaf0cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['MEDICAL_UNIT'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a216e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not very informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69871bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['ICU'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987c8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostly missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a439af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid['DATE_DIED'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ea1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostly missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74629b4f",
   "metadata": {},
   "source": [
    "Stays standing 'classification', 'patient type'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b220c33f",
   "metadata": {},
   "source": [
    "To make the decision between these two variables we did some research to gain some domain knowledge and spoke directly to some first responders during the covid 19 pandemic, that suggested that the information about whether or not a patient needed to be hospitalized was more valuable than the results of the covid test.\n",
    "This is the case since some patients might have tested positive for covid 19, but because of mild symptoms and overall good health were sent back home to be treated, and what actually really put a strain on health structures was the number of people in need to be hospitalized. Because of this we are going to use 'patient type' as our target for this study.\n",
    "We are also going to drop all the other variables related to hospitalization since those contain knowledge about the hospitalization of the patient, while what we are trying to predict is the amout of people that would need to be hospitalized, based on previous knowledge so this is not a type of information we would have, if we wanted to use the model again on other data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1eb78f",
   "metadata": {},
   "source": [
    "So target should be patient type and all the other hospital related variables should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_covid.drop(['USMER', 'MEDICAL_UNIT', 'INTUBED', 'CLASIFFICATION_FINAL', 'ICU', 'DATE_DIED'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7958beb8",
   "metadata": {},
   "source": [
    "The missing values are catalogued as 97 or 99. So I have to look for these values to understand how many null values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c3f82f",
   "metadata": {},
   "source": [
    "Will need to find a way to replace the missing values for pregnant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    print(df[i].value_counts(normalize=True))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1ae4d8",
   "metadata": {},
   "source": [
    "97, 98 and 99 represent missing values for all the columns except 'AGE'.\n",
    "<br>For some categories the missing values are so little that it's worth just dropping them. <br>For the two categories with the most missing values, 'PREGNANT' and 'PNEUMONIA' we will proceed to impute them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d481c4b",
   "metadata": {},
   "source": [
    "We will temporarily remove the 'age' column as in this one 97, 98 and 99 are actually real values and not missing values.\n",
    "<br> We will work on this column first to remove the outliers, then we will drop it from the dataset and reeinsert it once we dealt with the missing values for the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4f6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "age=df['AGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(age);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7db3c2",
   "metadata": {},
   "source": [
    "Even if we cannot be certain about this, since there is no information about this on the dataset, we can safely assume that values for age that are above 110 are probably typos or outliers. It might also be the way that it was inputed when the value of 'age' for that patient was missing: since there are no NaN values and yet, 97 98 and 99 which were used in the other columns to indicate missing values, clearly cannot be used in this one.\n",
    "So we will remove the columns that have the age value>110."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df['AGE']>110].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349bc913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AGE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcd01dc",
   "metadata": {},
   "source": [
    "Now that we have taken care of the outliers for this column in the Dataframe we can remove it to add it again once we finish the rest of the data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da28e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('AGE', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    df[i]=df[i].replace([97,98,99], np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add36530",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"I could replace the missing values using percentages OR I could do it using KNN OR I could do it direclty in the decision tree/random forest.\n",
    "For now let me replace them in this easier percentage way, then if I have time later I will try the other two ways.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a824cdc",
   "metadata": {},
   "source": [
    "As we saw before most missing values are in the column \"PREGNANT\".\n",
    "<br>We want to replace them but not just with the mode, but keeping the same percentage of values from the original data.\n",
    "<br>We will look at how the percentage is distributed, filtering out for now the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a08b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preg=pd.DataFrame()\n",
    "preg=df['PREGNANT']\n",
    "preg.drop(preg.loc[preg>3].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preg.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6866e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PREGNANT'].fillna(np.random.choice([1, 2], \n",
    "                                    p=[0.02,0.98]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba82b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PREGNANT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dbfd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PREGNANT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8af95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a614bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df, age], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63214548",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d63875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d9a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dba8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Correlation Matrix see if there's a better place for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1354c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 12))\n",
    "sns.heatmap(df.corr(), center=0, ax=ax, annot=True, mask=np.triu(np.ones_like(df.corr(), dtype=bool)), cmap=\"Blues\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b9736f",
   "metadata": {},
   "source": [
    "Now to follow the usual convention of one hot encoding I want to change the values 2 which means no into 0.\n",
    "<br>This is true for all the columns except our target, 'PATIENT_TYPE' where 1 means they returned home and 2 means they were hospitalized. I will do this separately, and then assign the column to y.\n",
    "For X I will do the necessary changes to df and then concat with 'AGE' that I dropped before.\n",
    "<br>For sex it is going to be 1 for female and 0 for male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b12c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['PATIENT_TYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have to redifine age again because the old onw has some null values that I dropped.\n",
    "age=df['AGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9911af24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PATIENT_TYPE','AGE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7b7b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ebb759",
   "metadata": {},
   "source": [
    "Changing to zero and 1 for the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fffc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.replace(1,0)\n",
    "y=y.replace(2, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78d0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bab9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.concat([df,age], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ddc723",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d28ce8e",
   "metadata": {},
   "source": [
    "At this point I took care of the missing values and I don't need to do one hot encoding.\n",
    "<br>I have my X and y, I can divide in train and test and start trying some models.\n",
    "<br>But if I want to use KNN first (and I do) I have to scale first, specifically age needs to be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Another thing I could try later to improve the model is instead of scaling the age to divide it into bins. Like 10 years for each bin and one hot encode that.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf8a4a",
   "metadata": {},
   "source": [
    "### Splitting into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2325e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad4024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "# Transform the training and test sets\n",
    "scaled_data_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert into a DataFrame\n",
    "X_train = pd.DataFrame(scaled_data_train, columns=X.columns)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd76e90",
   "metadata": {},
   "source": [
    "### Preliminary model with Logistic Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839242e9",
   "metadata": {},
   "source": [
    "A simple model that we can try is Logistic Regression.<br> I works similarly to Linear Regression but it can make predictions on categorical data, splitting continuous intervals into beams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef2f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=500, random_state=19)\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e2f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_log = logreg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddfb021",
   "metadata": {},
   "source": [
    "We will take a chance here to define a few functions that will help us preview our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e01c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defined so that I can use it for test or train\n",
    "def print_metrics(labels, preds):\n",
    "    print(\"Precision Score: {}\".format(precision_score(labels, preds)))\n",
    "    print(\"Recall Score: {}\".format(recall_score(labels, preds)))\n",
    "    print(\"Accuracy Score: {}\".format(accuracy_score(labels, preds)))\n",
    "    print(\"F1 Score: {}\".format(f1_score(labels, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e29d5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics(model, labels, preds):\n",
    "    results=[]\n",
    "    results.append(model)\n",
    "    results.append(['precision', (precision_score(labels, preds))])\n",
    "    results.append(['recall', (recall_score(labels, preds))])\n",
    "    results.append(['accuracy', (accuracy_score(labels, preds))])\n",
    "    results.append(['f1', (f1_score(labels, preds))])\n",
    "    yhat = model.predict_proba(X_train)\n",
    "    yhat = yhat[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, yhat)\n",
    "    results.append(['auc', (auc(fpr,tpr))])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149be2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(labels, preds, cmap=None):\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    # To Normalize\n",
    "    cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    sns.heatmap(cmn, annot=True, fmt='.2f', cmap=\"OrRd\")\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd37fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(model):\n",
    "    with plt.style.context('seaborn-talk'):\n",
    "        print(f'{Fore.RED}Results for the model {model}{Style.RESET_ALL}')\n",
    "        print(f'{Fore.BLUE}TRAIN{Style.RESET_ALL}')\n",
    "        y_preds_train=model.predict(X_train)\n",
    "        print_metrics(y_train, y_preds_train)\n",
    "        roc_score_train = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
    "        print(f\"Train Roc_Auc Score: {roc_score_train :.2%}\")\n",
    "        print('Confusion Matrix Train:')\n",
    "        plot_matrix(y_train, y_preds_train)\n",
    "        print(f'{Fore.GREEN}TEST{Style.RESET_ALL}')\n",
    "        y_preds_test=model.predict(X_test)\n",
    "        print_metrics(y_test, y_preds_test)\n",
    "        roc_score_test = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "        print(f\"Test Roc_Auc Score: {roc_score_test :.2%}\")\n",
    "        print('Confusion Matrix Test:')\n",
    "        plot_matrix(y_test, y_preds_test)\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d4771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(models, labels):\n",
    "    colors=['blue', 'green', 'k', 'purple','orange', 'm', 'c', 'b', 'lime' ]\n",
    "    lines=['dashed', 'dashdot', 'dotted', 'dashed', 'dashdot', 'dotted', 'dashed', 'dashdot', 'dotted']\n",
    "    plt.figure(figsize=(10,8))\n",
    "    for i, j, k in zip(models, lines, colors):\n",
    "        yhat = i.predict_proba(X_train)\n",
    "        yhat = yhat[:, 1]\n",
    "        fpr, tpr, thresholds = roc_curve(y_train, yhat)\n",
    "        plt.plot(fpr, tpr, label=i, alpha=0.6, linestyle=j, color=k, linewidth=3)\n",
    "    plt.plot([0, 1], [0, 1], color='indigo', linestyle='--', label='No Skill')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2afc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_roc(model):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    yhat = i.predict_proba(X_train)\n",
    "    yhat = yhat[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, yhat)\n",
    "    plt.plot(fpr, tpr, label='train', alpha=0.6, linestyle='dashed', color='forestgreen', linewidth=3)\n",
    "    yhat_test = i.predict_proba(X_test)\n",
    "    yhat_test = yhat_test[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, yhat_test)\n",
    "    plt.plot(fpr, tpr, label='test', alpha=0.6, linestyle='dashdot', color='firebrick', linewidth=3)\n",
    "    plt.plot([0, 1], [0, 1], color='indigo', linestyle='--', label='No Skill')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# with Seaborn\n",
    "def plot_roc(models, labels):\n",
    "#    markers=[ '1','2','3','4','+','*', 'x']\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in models:#, markers, colors):\n",
    "        yhat = i.predict_proba(X_train)\n",
    "        yhat = yhat[:, 1]\n",
    "        fpr, tpr, thresholds = roc_curve(y_train, yhat)\n",
    "        sns.lineplot(x=fpr, y=tpr, label=i, palette=\"flare\", lw=0.5)#, marker=j, alpha=0.6, color=k)#linewidth=0.5,\n",
    "    sns.lineplot([0, 1], [0, 1], color='navy', linestyle='--', label='No Skill')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb1f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_train, pred_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix(y_train, pred_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ba630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc([logreg], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_roc(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba51e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resu_logreg=save_metrics(logreg, y_train, pred_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fcf51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resu_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8db95ad",
   "metadata": {},
   "source": [
    "### Decision tree\n",
    "The Logistic Regression Model will be kept as our baseline model.\n",
    "<br>We will try next with a Decision Tree, and see if it performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfed028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the tree\n",
    "DT1 = DecisionTreeClassifier(criterion='entropy', random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79211af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tree\n",
    "DT1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b8182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the tree\n",
    "print(\"For the train with decision tree:\\n\")\n",
    "preds_train_DT1 = DT1.predict(X_train)\n",
    "model_results(DT1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca347104",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc([logreg,DT1], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e983a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_roc(DT1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae4ca2",
   "metadata": {},
   "source": [
    "Another feature that we have with decision trees is that we can extract their feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acfa847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure(figsize=(5,5))\n",
    "    #not sure why when I add np.sort in front of model feature it changes\n",
    "    plt.barh(range(n_features), (model.feature_importances_), align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train.columns.values) \n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeec364",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(DT1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13031f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resu_DT1=save_metrics(DT1, y_train, preds_train_DT1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a66fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resu_DT1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f9bec7",
   "metadata": {},
   "source": [
    "A few more information that we can retrieve about our tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2384c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Decision Tree has {DT1.tree_.node_count} nodes with a maximum depth of {DT1.tree_.max_depth}.')\n",
    "print(f'Model Accuracy for train data: {DT1.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da463c8c",
   "metadata": {},
   "source": [
    "This is not so bad as a result. But we have to ekep in mind that because of our class imbalance (80% of the patients returned home and 20% got hospitalized) a baseline model would have an accuracy of 80%.\n",
    "<br><br>\n",
    "Also - given our situation I would actually like to have a higher recall than accuracy. With a high recall it means I am getting more false positives because I am decreasing the thershold, but that is what I want most times in 'medical situations', because I would rather have a false positive than a false negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf67efbc",
   "metadata": {},
   "source": [
    "### Class Imbalance\n",
    "<br> One thing we have not considered yet is the fact that the classes of our target (patients sent home vs. patients hospitalized) are not balanced. They are not present equally in our dataset but around 80% of the patients were sent home and only 20% were hospitalized, as we saw from the split of the data for that column.\n",
    "<br> This means that a very basic model that simply predicts all the patients to be sent home would have an 80% accuracy, that's the baseline.\n",
    "<br> We have a way to counteract this problem by balancing the classes with a decision tree and that is what we are going to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_bal = DecisionTreeClassifier(criterion='entropy', class_weight='balanced', random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ae999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_bal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train_DTbal = DT_bal.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e1b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the tree\n",
    "print(\"Results with Decision Tree considering class imbalance:\\n\")\n",
    "model_results(DT_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc([logreg, DT1, DT_bal], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdc8e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_roc(DT_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7691f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(DT_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d4d922",
   "metadata": {},
   "source": [
    "As we can see from the confusion matrix we started to have more False Positives and the predictions of the majority class (0, people returned home) has decreased. This reflects also in the accuracy score and F1 score.\n",
    "<br> But on the bright side the predictions for the minority class (1, hospitalized) have improved, with less false negatives and a recall that went from 0.63 to 0.77.\n",
    "<br> This is a matter of choice for the stakeholder, which model to use. The Decision tree without class imbalance leads to an overall more precise model: less falses overall, negative and positive, more patients categorized correctly.\n",
    "<br> On the other hand the model that accounts for class imbalance makes more mistakes, has lower accurcay precision and F1 score, but it has overall less false negatives.\n",
    "<br>Given the specific problem we would recommend staying on the safer side, trying to minimize the false negatives then the false positives, because it would be less of a loss to be prepared for one extra patient that doesn't ultimately need to be hospitalized, rather then not being ready with the equippment for one that actually needs to be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60033152",
   "metadata": {},
   "source": [
    "### PROBABLY NOT DOING THIS GridSearchCV for Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff260600",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 1, 5, 10, 20],\n",
    "    'min_samples_split': [0.1, 0.2, 0.5, 0.75],\n",
    "    'min_samples_leaf':[1,3,5,10]\n",
    "}\n",
    "\n",
    "gs_tree = GridSearchCV(DT_bal, param_grid, cv=3)\n",
    "gs_tree.fit(X_train, y_train)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"gstree_accuracy=gs_tree.best_score_ \n",
    "pred_gstree=gs_tree.predict(X_train)\n",
    "print(f\"Testing Accuracy: {gstree_accuracy:.2%}\")\n",
    "print(\"\")\n",
    "# Mean training score\n",
    "#dt_gs_training_score = np.mean(gs_tree.cv_results_['mean_train_score'])\n",
    "# Mean test score\n",
    "#dt_gs_testing_score = gs_tree.score(X_test,y_test)\n",
    "#print(f\"Mean Training Score: {dt_gs_training_score :.2%}\")\n",
    "#print(f\"Mean Test Score: {dt_gs_testing_score :.2%}\")\n",
    "print(f\"Best Parameter Combination Found During Grid Search:{gs_tree.best_params_}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5f477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###model_results(gs_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f0a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###resu_gstree=save_metrics(gs_tree, y_train, pred_gstree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01779706",
   "metadata": {},
   "outputs": [],
   "source": [
    "###best_tree=DecisionTreeClassifier(criterion='gini', class_weight='balanced', max_depth=1, min_samples_split=0.1, min_samples_leaf=1, random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f795ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "###best_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d396dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "###preds_best3 = best_tree.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###print(\"Results with best Decision Tree considering class imbalance:\\n\")\n",
    "###model_results(best_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f479fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "###resu_best3=save_metrics(best_tree, y_train, preds_best3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7a22f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###resu_gstree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35f7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "###resu_best3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967aa4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "###plot_roc([logreg, DT1, DT_bal, best_tree], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f4396c",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eda6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit a RandomForestClassifier\n",
    "forest = RandomForestClassifier(random_state=19)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69867f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training accuracy score\n",
    "forest.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d1f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_for=forest.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a849a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be the accuracy\n",
    "#mean_rf_cv_score = np.mean(cross_val_score(forest, X_train, y_train, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b489f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_rf_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5946da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96da2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc([logreg, DT1, DT_bal, forest], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9fab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_roc(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e4dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resu_forest=save_metrics(forest, y_train, preds_for)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6abb24",
   "metadata": {},
   "source": [
    "### Random Forest class imbalance:\n",
    "Now accounting for the class imbalance in Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eccb3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_bal = RandomForestClassifier(random_state=19, class_weight='balanced')\n",
    "forest_bal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e1c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training accuracy score\n",
    "forest_bal.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fde49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_forbal=forest_bal.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e0fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(forest_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c9f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc([logreg, DT1, DT_bal, forest, forest_bal], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df69ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_roc(forest_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resu_forbal=save_metrics(forest_bal, y_train, preds_forbal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d079463",
   "metadata": {},
   "source": [
    "### GridSearchCV for Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the grid with parameters:\n",
    "\n",
    "rf_param_grid = { 'n_estimators':[10,30,100],\n",
    "                 'criterion': ['gini', 'entropy'],\n",
    "                 'max_depth': [None, 6, 10, 30],\n",
    "                 'min_samples_split':[5, 10],\n",
    "                 'min_samples_leaf':[3, 6]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf0ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" code with which we ran the GridSearchCV\n",
    "rf_grid_search = GridSearchCV(forest_bal, rf_param_grid,cv=3)\n",
    "rf_grid_search.fit(X_train, y_train)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d485dc4",
   "metadata": {},
   "source": [
    "Since the model took a very long time to fit I am going to pickle it, to save it for a later rerun without it having to fit again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0bb8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'CVforest.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee24e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" code with which we saved the model\n",
    "# save the model to disk\n",
    "\n",
    "joblib.dump(rf_grid_search, filename)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4fc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some time later...\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe71d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_accuracy=loaded_model.best_score_ \n",
    "best_params=loaded_model.best_params_\n",
    "print(f\"Testing Accuracy: {forest_accuracy:.2%}\")\n",
    "print(\"\")\n",
    "print(f\"Best Parameters:{best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53efc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_CV1 = RandomForestClassifier(random_state=19,class_weight='balanced','criterion':'entropy',\n",
    "                                 'max_depth': 6, 'min_samples_leaf': 6, 'min_samples_split': 5, 'n_estimators': 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a492681",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_CVl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3113d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_forCV1=for_CV1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be86fe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resu_forCV1=save_metrics(for_CV1, y_train, preds_forCV1)\n",
    "model_results(for_CV1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f18f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc([logreg, DT1, DT_bal, forest, forest_bal, for_CV1], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575c8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_roc(for_CV1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_results(loaded_model) I do not think this makes sense but lets hear from Eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dae46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid2 = { 'n_estimators':[20,30,40],\n",
    "                 'criterion': ['gini'],\n",
    "                 'max_depth':[None],\n",
    "                 'min_samples_split':[3,5],\n",
    "                 'min_samples_leaf':[5, 10, 20]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ab176",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code with which we ran the second grid search\n",
    "rf_grid_search2 = GridSearchCV(forest_bal, rf_param_grid2,cv=3)\n",
    "rf_grid_search2.fit(X_train, y_train)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b764d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = 'forGrid2.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e367346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" code with which we saved the model\n",
    "# save the model to disk\n",
    "\n",
    "joblib.dump(rf_grid_search2, filename2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79581e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some time later...\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model2 = joblib.load(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0d9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_accuracy=loaded_model2.best_score_ \n",
    "best_params=loaded_model2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aa5141",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Testing Accuracy: {forest_accuracy:.2%}\")\n",
    "print(\"\")\n",
    "print(f\"Best Parameters:{best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b4b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_CV2 = RandomForestClassifier(random_state=19,class_weight='balanced','criterion': 'gini', 'max_depth': None, \n",
    "                                 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec303eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_CV2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e510b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_forCV2=for_CV2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc941e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(for_CV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ded53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc([logreg, DT1, DT_bal, forest, forest_bal, for_CV1, for_CV2], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21dccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_roc(for_CV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3ab8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid3 = { 'n_estimators':[10, 15],\n",
    "                 'criterion': ['entropy'],\n",
    "                 'max_depth': [None,3,6],\n",
    "                 'min_samples_split':[1,3,5],\n",
    "                 'min_samples_leaf':[6, 10, 20]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code with which we ran the third gridsearch\n",
    "rf_grid_search3 = GridSearchCV(forest_bal, rf_param_grid,cv=3)\n",
    "rf_grid_search3.fit(X_train, y_train)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9edb387",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename3 = 'CVforest3.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab0570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code with which we saved the third gridserch\n",
    "joblib.dump(rf_grid_search3, filename3)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some time later...\n",
    "\n",
    "# load the model from disk\n",
    "loaded_model3 = joblib.load(filename3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c51bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_accuracy=loaded_model3.best_score_ \n",
    "best_params=loaded_model3.best_params_\n",
    "print(f\"Testing Accuracy: {forest_accuracy:.2%}\")\n",
    "print(\"\")\n",
    "print(f\"Best Parameters:{best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4bbb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_CV3 = RandomForestClassifier(random_state=19,class_weight='balanced','criterion': 'entropy', 'max_depth': 6,\n",
    "                                 'min_samples_leaf': 6, 'min_samples_split': 5, 'n_estimators': 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c4d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_CV3.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a684ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_forCV3=for_CV3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(for_CV3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2995f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc([logreg, DT1, DT_bal, forest, forest_bal,for_CV1, for_CV2, for_CV3], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_ROC(for_CV3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7f1c2f",
   "metadata": {},
   "source": [
    "### Best Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d182613a",
   "metadata": {},
   "source": [
    "Then I will run a forest with those best parameters we just found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78728e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_forest = RandomForestClassifier(n_estimators= 30 , criterion= 'gini', max_depth= None, \n",
    "#                    min_samples_split=5, min_samples_leaf=6, random_state=19, class_weight='balanced')\n",
    "#best_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ypreds_train_bestfor = best_forest.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Results for best Random Forest:\\n\")\n",
    "\n",
    "#print_metrics(y_train, ypreds_train_bestfor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_results(best_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17d3061",
   "metadata": {},
   "source": [
    "### Including class imbalance: THIS SHOULD NOT BE NECESSARY ALREADY INCLUDED ON TOP\n",
    "Now we will also use the balancing of the classes since we saw before that helped improving the recall rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_forest_bal = RandomForestClassifier(n_estimators= 30 , criterion= 'gini', max_depth= None, \n",
    "#min_samples_split= 5, min_samples_leaf=6, \n",
    "#                                     class_weight='balanced',random_state=19,)\n",
    "#best_forest_bal.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61c0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ypreds_train_bestfor_bal = best_forest_bal.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2043174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Results for best Random Forest Balanced:\\n\")\n",
    "\n",
    "#print_metrics(y_train, ypreds_train_bestfor_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfdc260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_results(best_forest_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193a0ab0",
   "metadata": {},
   "source": [
    "### XGBooster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b034b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate XGBClassifier\n",
    "xgb_model = xgb.XGBClassifier(random_state=19)\n",
    "\n",
    "# Fit XGBClassifier\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on training and test sets\n",
    "xgb_preds = xgb_model.predict(X_train)\n",
    "#test_preds = DT1.predict(X_test)\n",
    "\n",
    "# Accuracy of training and test sets\n",
    "#training_accuracy = accuracy_score(y_train, training_preds)\n",
    "#test_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "#print('Training Accuracy: {:.4}%'.format(training_accuracy * 100))\n",
    "#print('Validation Accuracy: {:.4}%'.format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results for best Random Forest with XGBoost:\\n\")\n",
    "\n",
    "print_metrics(y_train, xgb_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fccea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec512288",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc([logreg, DT1, DT_bal, forest, forest_bal,for_CV1, for_CV2, for_CV3, xgb_model], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f27db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_roc(xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3315f3",
   "metadata": {},
   "source": [
    "# To draw some conclusions:\n",
    "Now in order to draw some conclusions let us look at the results of the different models together and we will plot the ROC curve for all the different models we saw.\n",
    "<br>Once we can identify the best model we can see what the most important features were for that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models=[DT1, DT_bal, logreg, forest, best_forest, best_forest_bal, xgb_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b71f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"colors = sns.color_palette('Set1')\n",
    "aucs=[]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "for i in (models):\n",
    "    \n",
    "    yhat = i.predict_proba(X_train)\n",
    "    yhat = yhat[:, 1]\n",
    "    #fpr, tpr, thresholds= roc_curve(y_train, yhat)\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, yhat)\n",
    "    #plot_roc_curve(DT1, y_test, yhat)\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(fpr, tpr, label=i)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    aucs.append(auc(fpr, tpr))\n",
    "#    print('AUC for {}: {}'.format(i, auc(fpr, tpr)))\n",
    "#    print('-------------------------------------------------------------------------------------')\n",
    "#    lw = 2\n",
    "#    plt.plot(fpr, tpr,\n",
    "#             lw=lw, label='ROC curve {}'.format(i))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--', label='No Skill')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1f4f13",
   "metadata": {},
   "source": [
    "### I SHOULD CHANGE THIS SINCE I ALREADY SAVED THE RESULTS DOWN THE LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d160d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"precisions=[]\n",
    "recalls=[]\n",
    "accuracies=[]\n",
    "F1s=[]\n",
    "for i in (models):\n",
    "    print(f\"{Fore.BLUE} Model {Style.RESET_ALL}\", i)\n",
    "    preds=i.predict(X_train)\n",
    "    precisions.append(precision_score(y_train, preds))\n",
    "    recalls.append(recall_score(y_train, preds))\n",
    "    accuracies.append(accuracy_score(y_train, preds))\n",
    "    F1s.append(f1_score(y_train, preds))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### SORT THIS DF BY SOMETHING\n",
    "\n",
    "results=pd.DataFrame([])\n",
    "results['model']=models\n",
    "results['precision']=precisions\n",
    "results['recall']=recalls\n",
    "results['accuracy']=accuracies\n",
    "results['F1']=F1s\n",
    "results['AUC']=aucs\n",
    "results\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here I would compare just the 2/3 best confusion matrices\n",
    "#for i in (models):\n",
    "#    preds=i.predict(X_train)\n",
    "#    print(f\"{Fore.BLUE} Model {Style.RESET_ALL}\", i)\n",
    "#    plot_matrix(y_train, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"predictions=[]\n",
    "plt.figure(figsize=(15,15))\n",
    "#    fig = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "for i in models_fi:\n",
    "    preds=i.predict(X_train)\n",
    "    predictions.append(preds)\n",
    "    print(i)\n",
    "    cm = confusion_matrix(y_train, preds)\n",
    "    cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cmn, annot=True, fmt='.2f', cmap='BuPu')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "plt.show(block=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_fi=[logreg, DT1, DT_bal, forest, forest_bal,for_CV1, for_CV2, for_CV3, xgb_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12e1106",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_b=[DT_bal, forest_bal, xgb_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e8ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "colors=['black', 'purple','blue', 'red','orange', 'yellow']\n",
    "f, ax = plt.subplots(figsize=(12, 15))\n",
    "for i, j in zip(models_b, colors):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.barh(range(n_features), (i.feature_importances_), alpha=0.7, color=j)\n",
    "    plt.yticks(np.arange(n_features), X_train.columns.values)\n",
    "    plt.legend()\n",
    "#sns.barplot(x=\"total\", y=\"abbrev\", data=crashes,\n",
    "#            label=\"Total\", color=\"b\")\n",
    "\n",
    "# Plot the crashes where alcohol was involved\n",
    "#sns.set_color_codes(\"muted\")\n",
    "#sns.barplot(x=\"alcohol\", y=\"abbrev\", data=crashes,\n",
    "#            label=\"Alcohol-involved\", color=\"b\")\n",
    "\n",
    "# Add a legend and informative axis label\n",
    "    ax.legend (models_fi)\n",
    "    ax.set(ylabel=\"features\", xlabel=\"Feature Importance\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3127ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Here if I want I could create a df with all the feature importances. But maybe not necessary.\n",
    "# Feature Importance\n",
    "feat=[]\n",
    "imp=[]\n",
    "mod=[]\n",
    "for i in models_b:\n",
    "    feature_used = df.columns\n",
    "    for fi, feature in zip(i.feature_importances_, feature_used):\n",
    "        imp.append(fi)\n",
    "        feat.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp=pd.DataFrame([])\n",
    "feat_imp['model']=mod\n",
    "feat_imp['features']=feat\n",
    "feat_imp['importance']=imp\n",
    "\n",
    "feat_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4713ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp['model'][0:13]='Tree Balanced'\n",
    "feat_imp['model'][13:26]='Forest Balanced'\n",
    "feat_imp['model'][26:]='XGB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0bfd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-poster')\n",
    "#plt.figure(figsize=(30,15))\n",
    "#features = sns.load_dataset(\"feat_imp\")\n",
    "\n",
    "# Draw a nested barplot by species and sex\n",
    "g = sns.catplot(\n",
    "    data=feat_imp, kind=\"bar\",\n",
    "    x=\"features\", y=\"importance\", hue=\"model\",aspect=20/15\n",
    "#    errorbar=\"sd\", palette=\"dark\", alpha=.6, height=6\n",
    ")\n",
    "g.set_axis_labels(\"\", \"Feature Importance\")\n",
    "g.fig.set_figwidth(20)\n",
    "g.fig.set_figheight(10)\n",
    "g.set_xticklabels(labels=feat, rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b773554",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Clearly from the df the results are too many. \n",
    "Better to make a graph but maybe only with the best 3 models or it's gonna get confusing.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440eacab",
   "metadata": {},
   "source": [
    "From what we can observe the five most important features in our selection overall for the models are:\n",
    "    Pneumonia, Age, Diabetes, Renal Chronic, Hypertension and Sex?\n",
    "    IDK I have to study this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e52b48",
   "metadata": {},
   "source": [
    "I should take the best model,\n",
    "look at the list of Most Relevant Features,\n",
    "and then study them.\n",
    "For age, the only numeric one, I can divide it in bins and then plot for each bin the number of patients hospitalized.\n",
    "To get a sense of what patients are more at risk.\n",
    "For the other factors just say Drs can take care of those factors more, CDC could start campaigns and study more in depth people with those diseases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb3874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b210bedb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53c513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abcfe9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c50ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd8cf50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce333c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78708428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b92e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7097b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d61036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01f59603",
   "metadata": {},
   "source": [
    "### Code from Eva model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54227d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(model):\n",
    "    with plt.style.context('seaborn-talk'):\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "        # Create Confusion Matrix for the test set\n",
    "        plot_confusion_matrix(model, X_train, y_train, normalize = 'true', ax=ax1,  cmap = 'Greens')\n",
    "        ax1.grid(False)\n",
    "        ax1.set_title(\"Train Confusion Matrix\")\n",
    "        # Create Roc curve for the test and train for TP and FP rates\n",
    "        plot_roc_curve(model, X_train, y_train, ax=ax2, color='green', name ='Train ROC curve')\n",
    "#        plot_roc_curve(model, X_test, y_test, ax=ax2, color = blue, name ='Test ROC curve' )\n",
    "        ax2.plot([0, 1], [0, 1], color='black', lw=2, linestyle='-')\n",
    "        ax2.set_xlabel('False Positive Rate')\n",
    "        ax2.set_ylabel('True Positive Rate')\n",
    "        ax2.set_title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.show()\n",
    "        #Create a classification report\n",
    "        y_pred = model.predict(X_train)\n",
    "        print(classification_report(y_train, y_pred))\n",
    "        ######***NEW LINE*** Print CV ROC_AUC score, and roc_auc score for test/train\n",
    "        #Print CV ROC_AUC score\n",
    "        roc_score_train_cv = cross_val_score(estimator=model, X=X_train,  y=y_train,\n",
    "                                        cv=StratifiedKFold(shuffle=True), scoring='roc_auc').mean()\n",
    "        print(f\"Mean Cross Validated Roc_Auc Score: {roc_score_train_cv :.0%}\")\n",
    "        #print roc_auc for test and train\n",
    "        roc_score_train = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
    "        print(f\"Train Roc_Auc Score: {roc_score_train :.0%}\")\n",
    "#        roc_score_test = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "#        print(fTest Roc_Auc Score: {roc_score_test :.0%})\n",
    "        accuracy_train = model.score(X_train, y_train)\n",
    "#        accuracy_test = model.score(X_test, y_test)\n",
    "        print(f\"Train Accuracy Score: {accuracy_train :.0%}\")\n",
    "#        print(fTest Accuracy Score: {accuracy_test :.0%})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67646362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf7296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691bd7bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2486c0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e759594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa01dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
